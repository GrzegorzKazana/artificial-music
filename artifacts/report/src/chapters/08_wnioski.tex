\chapter{Wnioski}
{
    W niniejszej pracy przedstawiono jedynie jedno z możliwych podejść do rozwiązania problemu,
    jakim jest generowanie muzyki za pomocą metod uczenia maszynowego. Głównym celem podjęcia 
    tego tematu jest przekraczanie kolejnych granic, które jeszcze w nieodległej przeszłości
    wydawały się absolutnie nieprzekraczalne. Pomimo nie osiągnięcia w pełni satysfakcjonujących 
    rezultatów, cały proces był niezwykle pouczający. 
    Liczność oraz daty powstania dostępnych źródeł literaturowych wskazują, że problem jest aktualny 
    i wciąż prowadzone są badania na temat zastosowania metod sztucznej inteligencji w zadaniach, 
    które można określić mianem twórczych. Sama treść studiowanych prac przedstawia mnogość 
    różnych podejść i do powyższego problemu.
    Kształcącym elementem pracy był również rozległy proces wstępnej analizy możliwych sposobów
    rozwoju projektu. Poczynając od porównania odmiennych formatów danych muzycznych, opracowaniu 
    numerycznej reprezentacji danych, doboru zbioru treningowego oraz samego projektu architektury
    modelu. Razem z opracowywaniem metod intuicyjnie efektywniejszych, przykładowo takich jak automatyczne wykrywanie
    najczęstszych wartości rytmicznych, pozwalające na dyskretyzację reprezentacji czasowej bez
    manualnego definiowania zbioru dozwolonych wartości, tworzone również były założenia
    ograniczające wyniki i potencjalne zastosowania. Do ograniczeń opisanego procesu można 
    zaliczyć między innymi niemożliwość reprezentowania utworów wieloinstrumentowych, ograniczony 
    słownik wielodźwięków oraz stratność przekształcenia plików midi na macierze i ponownego przetworzenia
    macierzy na plik midi.
    Rozdział dotyczący uczenia modelu zaprezentował podstawowe kroki, jakie należy poczynić podchodząc do
    dowolnego problemu uczenia maszynowego. Do najważniejszych należy projekt architektury modelu,
    dobór miar i funkcji kosztów oraz walidacja modelu. Opisywany etap pracy również pozwolił na zapoznanie 
    się z współczesnymi narzędziami ułatwiającymi wszelkie zadania uczenia maszynowego, takimi jak Tensorflow, 
    TensorBoard i Google Colab. 

    Otrzymane rezultaty nie spełniają wszystkich oczekiwań, lecz wykazują conajmniej poprawność i częściowy
    sukces obranego podejścia. Jedną z przyczyn zastrzeżeń potencjalnie mógł być sam zbiór danych, nie 
    zawierający wystarczającej różnorodności pozwalającej na skuteczną generalizację zależności zawartych 
    w danych i opracowanie reguł je zawierających.

    W celu osiągnięcia rezultatów spełniających bardziej rygorystyczne oczekiwania, słusznym krokiem byłoby
    ponowne wybranie zbioru danych treningowych, tym razem składającego się z większej ilości próbek i nieobarczonego
    wadą opisaną w rozdziale poświęconym procesowi uczenia. 
    Wraz z zmianą danych oraz ich objętości, konieczna byłaby ponowna parametryzacja modelu i procesu uczenia.

    Interesującym kierunkiem, który jest podatny na dalszą eksplorację są inne rodzaje architektur sieci neuronowych.
    Pomimo że problem inherentnie opiera się na analizie sekwencji co silnie sugeruje wykorzystanie rekurencyjnych 
    sieci LSTM, możliwe są konstrukcje modeli odmienne od przytoczonych. Jedną z nich są modele typu 
    sequence-to-sequence encode-decoder, na których wyjściu i wejściu są sieci LSTM, lecz dane pomiędzy nimi są
    kompresowane do jednowymiarowego tensora, który potem jest ponownie przekształcany na sekwencję. 
    Alternatywnym podejściem szeroko stosowanym w problemach transferu stylu i generacji obrazów, 
    są modele generacyjno-adwersyjne (Generative-Adversial Models), składające się sieci generującej 
    próbki i sieci uczącej się rozróżniać oryginały od falsyfikatów.
}
