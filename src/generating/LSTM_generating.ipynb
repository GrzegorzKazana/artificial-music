{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "proj_base_path = '../../'\n",
    "data_base_path = '../../datasets'\n",
    "models_base_path = '../../pretrained_models'\n",
    "sys.path.append(os.path.join(os.getcwd(), proj_base_path))\n",
    "\n",
    "dataset_path = 'numpy/pokemon100ms_no_vel_transposed/meta/'\n",
    "dataset_file = '_dicted_dataset_ignore_ratio=0.05.npy'\n",
    "word_vectors_file = '_word_vectors_1000_ignore_ratio=0.05.wv'\n",
    "\n",
    "track_path = os.path.join(data_base_path, dataset_path, dataset_file)\n",
    "word_vectors_path = os.path.join(data_base_path, dataset_path, word_vectors_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = KeyedVectors.load(word_vectors_path, mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as K\n",
    "\n",
    "model_dir = 'lstm/embedded_16_128/'\n",
    "model_file = 'md_e1_t2019-10-12T11:21:54.h5'\n",
    "model = K.models.load_model(os.path.join(models_base_path, model_dir, model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(models_base_path, model_dir, 'samples')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f'saving samples to {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing and preparing seed generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generating.embedded_generating_seeds import seed_generators\n",
    "\n",
    "seed_gens = [\n",
    "    ('random_noise_seed', lambda length, input_size, wv, batch_size: seed_generators['random_noise_seed'](\n",
    "        length, input_size, scaler=2.0, batch_size=batch_size)),\n",
    "    ('zero_seed', lambda length, input_size, wv, batch_size: seed_generators['zero_seed'](\n",
    "        length, input_size, wv, batch_size=batch_size)),\n",
    "    ('const_frame_seed', lambda length, input_size, wv, batch_size: seed_generators['const_frame_seed'](\n",
    "        length, input_size, wv, batch_size=batch_size)),\n",
    "    ('short_frame_seed', lambda length, input_size, wv, batch_size: seed_generators['short_frame_seed'](\n",
    "        length, input_size, wv, batch_size=batch_size)),\n",
    "    ('multi_note_seed', lambda length, input_size, wv, batch_size: seed_generators['multi_note_seed'](\n",
    "        length, input_size, wv, batch_size=batch_size)),\n",
    "    ('multi_note_harmonic_seed', lambda length, input_size, wv, batch_size: seed_generators['multi_note_harmonic_seed'](\n",
    "        length, input_size, wv, batch_size=batch_size)),\n",
    "    ('const_frame_seed_noise', lambda length, input_size, wv, batch_size: seed_generators['const_frame_seed_noise'](\n",
    "        length, input_size, word_vectors=wv, batch_size=batch_size)),\n",
    "    ('short_frame_seed_noise', lambda length, input_size, wv, batch_size: seed_generators['short_frame_seed_noise'](\n",
    "        length, input_size, word_vectors=wv, batch_size=batch_size)),\n",
    "    ('multi_note_seed_noise', lambda length, input_size, wv, batch_size: seed_generators['multi_note_seed_noise'](\n",
    "        length, input_size, word_vectors=wv, batch_size=batch_size)),\n",
    "    ('multi_note_harmonic_seed_noise', lambda length, input_size, wv, batch_size: seed_generators['multi_note_harmonic_seed_noise'](\n",
    "        length, input_size, word_vectors=wv, batch_size=batch_size)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining generating constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.common.rw_np_mid import read_numpy_midi, save_numpy_midi\n",
    "from src.generating.generating import recurrent_generate\n",
    "from src.data_processing.embedding_sparse_notes.reverse_transform import np2sparse\n",
    "from src.data_processing.sparse_notes_quantized_time.np2mid import np2mid\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_LENGTH = 50\n",
    "SEQ_LENGTH = 400\n",
    "INPUT_SIZE = 16\n",
    "WINDOW_SIZE = 100\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, gen in seed_gens:\n",
    "    seed = gen(SEED_LENGTH, INPUT_SIZE, wv, BATCH_SIZE)\n",
    "    samples = recurrent_generate(\n",
    "        model, seed, SEQ_LENGTH, WINDOW_SIZE)\n",
    "    sparse_samples = [np2sparse(sample, wv)[0]\n",
    "                      for sample in samples]\n",
    "    for i, sample in enumerate(sparse_samples):\n",
    "        name = f'{model_file}_{name}_{time()}_{i}'\n",
    "        mid = np2mid(sample.toarray())\n",
    "        mid.save(f'{name}.mid')\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(sample.toarray().T[::-1, :])\n",
    "        fig.savefig(f'{name}.png', dpi=fig.dpi)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
