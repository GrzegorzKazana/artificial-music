{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont forget to switch to GPU if possible\n",
    "google_colab_env = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if google_colab_env:\n",
    "    from google.colab import drive\n",
    "    %tensorflow_version 1.x\n",
    "    drive.mount('/content/drive')\n",
    "    !git clone https://github.com/GrzegorzKazana/artificial-music.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing dataset, splitting tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "proj_base_path = ('/content/artificial-music' \n",
    "                  if google_colab_env else '../../../')\n",
    "\n",
    "data_base_path =  ('/content/drive/My Drive/artificial-music/datasets'\n",
    "                   if google_colab_env else '../../../datasets')\n",
    "\n",
    "models_base_path =  ('/content/drive/My Drive/artificial-music/pretrained_models' \n",
    "                     if google_colab_env else '../../../pretrained_models')\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), proj_base_path))\n",
    "\n",
    "dataset_path = 'numpy/pokemon_clustered_time'\n",
    "word_vectors_file = 'meta/_word_vectors_11000_ignore_ratio=0.05.wv'\n",
    "duration_dict_file = 'meta/durations_dict.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_path = os.path.join(data_base_path, dataset_path, word_vectors_file)\n",
    "with open(os.path.join(data_base_path, dataset_path, duration_dict_file)) as fp:\n",
    "    duration_dict = json.load(fp)\n",
    "\n",
    "tracks_path = os.path.join(data_base_path, dataset_path)\n",
    "track_paths = [os.path.join(tracks_path, f) for f in os.listdir(tracks_path) if f.endswith('.npz')]\n",
    "\n",
    "tracks = [sparse.load_npz(p).tocsr().toarray() for p in track_paths]\n",
    "\n",
    "for t in tracks: print(t.shape, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping ~0 duration class datapoints\n",
    "tracks = [t[t[:, 128] != 1] for t in tracks]\n",
    "tracks = [t for t in tracks if t.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading embedding + encoding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = KeyedVectors.load(word_vectors_path, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.sparse_notes_classified_time.embed_adapt import decode_note_vector_track, encode_frames, append_track_end  \n",
    "\n",
    "note_vecs, durations = zip(*[(t[:, :128], t[:, 128:]) for t in tracks])\n",
    "\n",
    "note_vecs = [encode_frames(sparse.csr_matrix(t), wv) for t in note_vecs]\n",
    "\n",
    "tracks_embedded = [np.concatenate((n_v, d), axis=1) for n_v, d in zip(note_vecs, durations)]\n",
    "\n",
    "len(tracks_embedded), tracks_embedded[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_gen(tracks, window_size_range=(20, 300), batch_size=16):\n",
    "    \"\"\"\n",
    "    tracks - list of np.arrays of shape (track_length, frame_size)\n",
    "    window_size - length of generated batch\n",
    "    batch_size - number of sequences in batch\n",
    "    \"\"\"\n",
    "    max_window_size = min([len(t) for t in tracks]) - 3\n",
    "    while True:\n",
    "        window_size = np.random.randint(window_size_range[0], min(max_window_size, window_size_range[1]))\n",
    "        # select #batch_size tracks\n",
    "        selected_track_indicies = [np.random.randint(0, len(tracks)) for _ in range(batch_size)]\n",
    "        # select sequence starting point for each track\n",
    "        sequence_indicies = [np.random.randint(0, len(tracks[sti]) - window_size - 2)\n",
    "                             for sti in selected_track_indicies]\n",
    "        \n",
    "        \n",
    "        # create slices for x and y\n",
    "        x_slice = lambda seqi: np.s_[seqi:seqi + window_size]\n",
    "        y_slice = lambda seqi: np.s_[seqi + 1:seqi + window_size + 1]\n",
    "        \n",
    "        x = [tracks[sti][x_slice(seqi)] for sti, seqi in zip(selected_track_indicies, sequence_indicies)]\n",
    "        y = [tracks[sti][y_slice(seqi)] for sti, seqi in zip(selected_track_indicies, sequence_indicies)]\n",
    "\n",
    "        yield np.stack(x), np.stack(y)\n",
    "        \n",
    "x, y = next(dataset_gen(tracks_embedded, (10, 50), 5))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as K\n",
    "\n",
    "NOTES_INPUT_SIZE = 16\n",
    "DURATION_INPUT_SIZE = 24\n",
    "\n",
    "DURATION_INPUT_DENSE_SIZE = 16\n",
    "\n",
    "MAIN_LSTM_SIZE = 256\n",
    "MAIN_DENSE_SIZE = 128\n",
    "\n",
    "NOTES_LSTM_SIZE = 64\n",
    "DURATION_LSTM_SIZE = 32\n",
    "\n",
    "NOTES_OUTPUT_DENSE = 32\n",
    "DURATION_OUTPUT_DENSE = 32\n",
    "\n",
    "NOTES_OUTPUT_SIZE = NOTES_INPUT_SIZE\n",
    "DURATION_OUTPUT_SIZE = DURATION_INPUT_SIZE\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "WINDOW_SIZE_RANGE = (10, 25)\n",
    "\n",
    "NOTES_INPUT_SHAPE = (None, NOTES_INPUT_SIZE)\n",
    "DURATION_INPUT_SHAPE = (None, DURATION_INPUT_SIZE)\n",
    "# None allows for variable seq_length between batches\n",
    "\n",
    "NOTES_INPUT_NAME = 'notes_input'\n",
    "DURATION_INPUT_NAME = 'duration_input'\n",
    "NOTES_OUTPUT_NAME = 'notes_output'\n",
    "DURATION_OUTPUT_NAME = 'duration_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load saved model\n",
    "model_path = 'lstm_lstm/embedded_16_128_stacked_32/embedded_16_128_stacked_32md_e200_t2019-10-09T09_59_31_cpu.h5'\n",
    "model = K.models.load_model(os.path.join(models_base_path, model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or create new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, CuDNNLSTM, Input, Concatenate\n",
    "rnn_layer = CuDNNLSTM if google_colab_env else LSTM\n",
    "\n",
    "x1 = Input(NOTES_INPUT_SHAPE, name=NOTES_INPUT_NAME)\n",
    "x2 = Input(DURATION_INPUT_SHAPE, name=DURATION_INPUT_NAME)\n",
    "x3 = Dense(DURATION_INPUT_DENSE_SIZE)(x2)\n",
    "\n",
    "h1 = Concatenate()([x1, x3])\n",
    "h2 = rnn_layer(MAIN_LSTM_SIZE, return_sequences=True)(h1)\n",
    "h3 = Dense(MAIN_DENSE_SIZE)(h2)\n",
    "\n",
    "g1 = rnn_layer(NOTES_LSTM_SIZE, return_sequences=True)(h3)\n",
    "g2 = Dense(NOTES_OUTPUT_DENSE)(g1)\n",
    "y1 = Dense(NOTES_OUTPUT_SIZE, name=NOTES_OUTPUT_NAME)(g2)\n",
    "\n",
    "i1 = rnn_layer(DURATION_LSTM_SIZE, return_sequences=True)(h3)\n",
    "i2 = Dense(DURATION_OUTPUT_DENSE)(i1)\n",
    "y2 = Dense(DURATION_OUTPUT_SIZE, name=DURATION_OUTPUT_NAME, activation='softmax')(i2)\n",
    "\n",
    "model = Model(inputs=[x1, x2], outputs=[y1, y2])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    NOTES_OUTPUT_NAME: 'mse',\n",
    "    DURATION_OUTPUT_NAME: 'categorical_crossentropy',\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    NOTES_OUTPUT_NAME: ['mse'],\n",
    "    DURATION_OUTPUT_NAME: ['categorical_accuracy'],\n",
    "}\n",
    "\n",
    "# maybe diffrent weights for outputs???\n",
    "\n",
    "model.compile(\n",
    "    loss=losses,\n",
    "    optimizer='adam', \n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.common.training_callbacks import ModelAndLogSavingCallback, GeneratingAndPlottingCallback\n",
    "\n",
    "# logging callback\n",
    "logging_path = 'lstm_clustered_time'\n",
    "experiment_name = f'embedded_clustered_time_{MAIN_LSTM_SIZE}_no_shortest'\n",
    "experiment_path = os.path.join(models_base_path, logging_path, experiment_name)\n",
    "os.makedirs(experiment_path, exist_ok=True)\n",
    "print(f'saving checkpoints and logs to {experiment_path}')\n",
    "\n",
    "# logging disabled for now\n",
    "log_callback = ModelAndLogSavingCallback(model, experiment_path, save_log_only=True)\n",
    "\n",
    "# generating callback\n",
    "from src.generating.generating import recurrent_generate\n",
    "from src.generating.embedded_clustered_time_generating_seeds import get_seed_generators\n",
    "from src.data_processing.common.helpers import pipe\n",
    "from src.data_processing.sparse_notes_classified_time.np2mid import np2sparse\n",
    "from src.data_processing.sparse_notes_classified_time.embed_adapt import decode_note_vector_track\n",
    "\n",
    "SEED_LENGTH = 5\n",
    "GENERATED_SEQ_LENGTH = 50\n",
    "GENERATING_WINDOW_SIZE = 15\n",
    "\n",
    "sd = get_seed_generators(duration_dict, ignore_shortest=True)\n",
    "\n",
    "def seed_generator():\n",
    "    return np.concatenate([\n",
    "        sd['random_noise_seed'](SEED_LENGTH, NOTES_INPUT_SIZE, batch_size=BATCH_SIZE // 4),\n",
    "        sd['zero_seed'](SEED_LENGTH, NOTES_INPUT_SIZE, word_vectors=wv, batch_size=BATCH_SIZE // 4),\n",
    "        sd['multi_note_harmonic_seed'](SEED_LENGTH, NOTES_INPUT_SIZE, word_vectors=wv, batch_size=BATCH_SIZE // 4),\n",
    "        sd['multi_note_harmonic_seed_noise'](SEED_LENGTH, NOTES_INPUT_SIZE, word_vectors=wv, batch_size=BATCH_SIZE // 4),\n",
    "    ], axis=0)\n",
    "\n",
    "sample_generator = lambda model, seed: recurrent_generate(\n",
    "    model, \n",
    "    seed, \n",
    "    GENERATED_SEQ_LENGTH, \n",
    "    GENERATING_WINDOW_SIZE, \n",
    "    is_binary=False,\n",
    "    transform_input=lambda x: (x[:, :, :NOTES_INPUT_SIZE], x[:, :, NOTES_INPUT_SIZE:]),\n",
    "    transform_output=lambda args: np.concatenate((args[0], args[1]), axis=2),\n",
    ")\n",
    "\n",
    "def tap(f):\n",
    "    def inner(x):\n",
    "        f(x)\n",
    "        return x\n",
    "    return inner\n",
    "\n",
    "def print_list(l):\n",
    "    for i, li in enumerate(l):\n",
    "        print(i, li)\n",
    "\n",
    "marker_end = np.zeros((BATCH_SIZE, 1, 40))\n",
    "marker_end[:, :, 16] = 1\n",
    "\n",
    "sparse_sample_generator = lambda model, seed: pipe(\n",
    "    sample_generator(model, seed),\n",
    "    # tap(lambda x: print(x.shape)),\n",
    "    # tap(lambda x: print_list(x.tolist()[0])),\n",
    "    # tap(lambda x: [print_list(np.split(np.argwhere(s)[:, 1], np.cumsum(np.unique(np.argwhere(s)[:, 0], return_counts=True)[1])[:-1])) for s in x]),\n",
    "    lambda x: np.concatenate((x, marker_end), axis=1),\n",
    "    lambda batch_of_samples: [\n",
    "        np2sparse(\n",
    "            np.multiply(decode_note_vector_track(s[:, :NOTES_INPUT_SIZE], wv, return_similarities=True)),\n",
    "            s[:, NOTES_INPUT_SIZE:],\n",
    "            duration_dict,\n",
    "            ppq=20,\n",
    "        ) for s in batch_of_samples],\n",
    ")\n",
    "\n",
    "gen_callback = GeneratingAndPlottingCallback(model, sparse_sample_generator, seed_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "mc_best = ModelCheckpoint(\n",
    "    os.path.join(experiment_path, 'model_best.h5'),\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "mc_last = ModelCheckpoint(\n",
    "    os.path.join(experiment_path, 'model_last.h5'),\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False,\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-2,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre training code\n",
    "from time import time\n",
    "epochs_elapsed = 0\n",
    "minutes_elapsed = 0\n",
    "\n",
    "def dataset_gen_split_inout(X, window_size_range, batch_size):\n",
    "    gen = dataset_gen(X, window_size_range, batch_size)\n",
    "    while True:\n",
    "        x, y = next(gen)\n",
    "        x_split = {\n",
    "            NOTES_INPUT_NAME: x[:, :, :NOTES_INPUT_SIZE],\n",
    "            DURATION_INPUT_NAME: x[:, :, NOTES_INPUT_SIZE:],\n",
    "        }\n",
    "        y_split = {\n",
    "            NOTES_OUTPUT_NAME: y[:, :, :NOTES_INPUT_SIZE],\n",
    "            DURATION_OUTPUT_NAME: y[:, :, NOTES_INPUT_SIZE:],\n",
    "        }\n",
    "        yield x_split, y_split\n",
    "\n",
    "# reserving last 25 notes for validation\n",
    "tracks_embedded_train = [t[:-25] for t in tracks_embedded]\n",
    "tracks_embedded_val = [t[-25:] for t in tracks_embedded]\n",
    "\n",
    "data_gen = dataset_gen_split_inout(tracks_embedded_train, WINDOW_SIZE_RANGE, BATCH_SIZE)\n",
    "test_gen = dataset_gen_split_inout(tracks_embedded_val, WINDOW_SIZE_RANGE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = 1000\n",
    "TEST_STEPS = 100\n",
    "\n",
    "start_time = time()\n",
    "model.fit_generator(\n",
    "    data_gen,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_gen,\n",
    "    validation_steps=TEST_STEPS,\n",
    "    callbacks=[log_callback, gen_callback, mc_best, mc_last] #mc, es]\n",
    ")\n",
    "\n",
    "minutes_elapsed += (time() - start_time) // 60\n",
    "epochs_elapsed += EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert gpu model to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'lstm_clustered_time_embedded/model_best.h5'\n",
    "model = K.models.load_model(os.path.join(models_base_path, model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.common.CUDNNLSTM_LSTM import cudnnlstm_to_lstm\n",
    "\n",
    "cpu_model = cudnnlstm_to_lstm(model)\n",
    "cpu_model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam', \n",
    "    metrics=[\"mean_squared_error\"],\n",
    ")\n",
    "\n",
    "K.models.save_model(cpu_model, os.path.join(models_base_path, model_path).replace('.h5', '_cpu.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
