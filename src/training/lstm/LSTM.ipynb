{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing dataset, splitting tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D#3,C4', 'D#3,C4', 'D#3,C4', ..., '<UNKNOWN>', '<UNKNOWN>',\n",
       "       '<TRACK_END>'], dtype='<U27')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "base_path = '../../../'\n",
    "sys.path.append(os.path.join(os.getcwd(), base_path))\n",
    "\n",
    "dataset_path = 'datasets/numpy/pokemon100ms_no_vel_transposed/meta/'\n",
    "dataset_file = '_dicted_dataset_ignore_ratio=0.05.npy'\n",
    "word_vectors_file = '_word_vectors_1000_ignore_ratio=0.05.wv'\n",
    "\n",
    "track_path = os.path.join(base_path, dataset_path, dataset_file)\n",
    "word_vectors_path = os.path.join(base_path, dataset_path, word_vectors_file)\n",
    "\n",
    "track = np.load(track_path)\n",
    "\n",
    "track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.embedding_sparse_notes.common import TRACK_END, UNKNOWN_FRAME\n",
    "\n",
    "track_split_points = np.where(track == TRACK_END)[0]\n",
    "\n",
    "# + 1, so split happens after <TRACK_END>, [:-1] to skip last, empty partition\n",
    "tracks = [t.tolist() for t in np.split(track, track_split_points + 1)][:-1]\n",
    "# tracks is now a list of lists of frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading embedding + encoding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 16), (2197, 16), (1920, 16), (361, 16), (552, 16), (1008, 16), (533, 16), (552, 16), (552, 16), (533, 16), (1008, 16), (361, 16), (2197, 16), (2197, 16), (2197, 16), (361, 16), (1920, 16), (552, 16), (1008, 16), (552, 16), (717, 16), (717, 16), (552, 16), (1008, 16), (552, 16), (1920, 16), (361, 16), (2197, 16), (2197, 16), (1920, 16), (552, 16), (1622, 16), (717, 16), (386, 16), (1008, 16), (1622, 16), (552, 16), (552, 16), (1622, 16), (1008, 16), (386, 16), (717, 16), (552, 16), (1622, 16), (1920, 16), (361, 16), (2197, 16), (2197, 16), (1920, 16), (361, 16), (552, 16), (717, 16), (1008, 16), (386, 16), (552, 16), (1008, 16), (1008, 16), (552, 16), (386, 16), (1008, 16), (1622, 16), (552, 16), (361, 16), (1920, 16), (2197, 16), (717, 16), (361, 16), (2197, 16), (1008, 16), (533, 16), (533, 16), (386, 16), (386, 16), (533, 16), (533, 16), (361, 16), (2197, 16), (1008, 16), (361, 16), (717, 16), (717, 16), (1622, 16), (2197, 16), (1920, 16), (533, 16), (361, 16), (533, 16), (533, 16), (361, 16), (1920, 16), (2197, 16), (1622, 16), (717, 16), (717, 16), (2197, 16), (361, 16), (717, 16), (1008, 16), (533, 16), (361, 16), (361, 16), (533, 16), (717, 16), (1920, 16), (361, 16), (2197, 16), (717, 16), (717, 16), (361, 16), (1622, 16), (2197, 16), (1920, 16), (1008, 16), (533, 16), (533, 16), (361, 16), (361, 16), (533, 16), (533, 16), (1008, 16), (361, 16), (1920, 16), (2197, 16), (1622, 16), (361, 16), (717, 16), (361, 16), (1622, 16), (1008, 16), (361, 16), (1920, 16), (361, 16), (361, 16), (1920, 16), (361, 16), (1622, 16), (361, 16), (717, 16), (361, 16), (361, 16), (2197, 16), (1622, 16), (1008, 16), (361, 16), (1920, 16), (1920, 16), (361, 16), (1008, 16), (1622, 16), (2197, 16), (361, 16), (361, 16), (717, 16), (361, 16), (1622, 16), (361, 16), (1008, 16), (2197, 16), (1920, 16), (1920, 16), (1008, 16), (2197, 16), (361, 16), (1622, 16), (361, 16), (1920, 16), (361, 16), (552, 16), (1622, 16), (361, 16), (1008, 16), (1920, 16), (533, 16), (533, 16), (1920, 16), (1008, 16), (361, 16), (1622, 16), (552, 16), (361, 16), (1920, 16), (1920, 16), (1622, 16), (552, 16), (386, 16), (1008, 16), (386, 16), (386, 16), (717, 16), (717, 16), (533, 16), (386, 16), (386, 16), (552, 16), (1008, 16), (386, 16), (1622, 16), (552, 16), (1920, 16), (1622, 16), (386, 16), (552, 16), (386, 16), (386, 16), (533, 16), (717, 16), (533, 16), (386, 16), (552, 16), (386, 16), (1622, 16), (2197, 16), (361, 16), (1622, 16), (386, 16), (361, 16), (386, 16), (533, 16), (717, 16), (717, 16), (533, 16), (386, 16), (386, 16), (361, 16), (2197, 16), (1622, 16), (386, 16), (361, 16), (533, 16), (361, 16), (552, 16), (717, 16), (717, 16), (552, 16), (361, 16), (533, 16), (386, 16), (361, 16), (386, 16), (1622, 16), "
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = KeyedVectors.load(word_vectors_path, mmap='r')\n",
    "\n",
    "def vectorize_frame(frame):\n",
    "    return wv[frame] if frame in wv else wv[UNKNOWN_FRAME]\n",
    "\n",
    "vectorized_tracks = [np.array([vectorize_frame(f) for f in t]) for t in tracks]\n",
    "for v in vectorized_tracks: print(v.shape, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 50, 16), (5, 50, 16))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataset_gen(tracks, window_size, batch_size):\n",
    "    \"\"\"\n",
    "    tracks - list of np.arrays of shape (track_length, frame_size)\n",
    "    window_size - length of generated batch\n",
    "    batch_size - number of sequences in batch\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # select #batch_size tracks\n",
    "        selected_track_indicies = [np.random.randint(0, len(tracks)) for _ in range(batch_size)]\n",
    "        # select sequence starting point for each track\n",
    "        sequence_indicies = [np.random.randint(0, len(tracks[sti]) - window_size - 2)\n",
    "                             for sti in selected_track_indicies]\n",
    "        \n",
    "        \n",
    "        # create slices for x and y\n",
    "        x_slice = lambda seqi: np.s_[seqi:seqi + window_size]\n",
    "        y_slice = lambda seqi: np.s_[seqi + 1:seqi + window_size + 1]\n",
    "        \n",
    "        x = [tracks[sti][x_slice(seqi)] for sti, seqi in zip(selected_track_indicies, sequence_indicies)]\n",
    "        y = [tracks[sti][y_slice(seqi)] for sti, seqi in zip(selected_track_indicies, sequence_indicies)]\n",
    "\n",
    "        yield np.stack(x), np.stack(y)\n",
    "        \n",
    "x, y = next(dataset_gen(vectorized_tracks, 50, 5))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as K\n",
    "\n",
    "INPUT_SIZE = 16\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = INPUT_SIZE\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "WINDOW_SIZE = 100\n",
    "\n",
    "INPUT_SHAPE = (None, INPUT_SIZE)\n",
    "# None allows for variable seq_length between batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1001 19:49:48.077003 4698133952 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = K.models.Sequential([\n",
    "    K.layers.LSTM(\n",
    "        HIDDEN_SIZE,\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        return_sequences=True,\n",
    "    ),\n",
    "    K.layers.Dense(\n",
    "        OUTPUT_SIZE,\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoints and logs to ../../../pretrained_models/lstm/embedded_16_128\n",
      "generating sequences of 300 using random_noise_seed\n"
     ]
    }
   ],
   "source": [
    "from src.training.common.training_callbacks import ModelAndLogSavingCallback, GeneratingAndPlottingCallback\n",
    "\n",
    "# logging callback\n",
    "logging_path = 'pretrained_models/lstm'\n",
    "experiment_name = f'embedded_{INPUT_SIZE}_{HIDDEN_SIZE}'\n",
    "experiment_path = os.path.join(base_path, logging_path, experiment_name)\n",
    "os.makedirs(experiment_path, exist_ok=True)\n",
    "print(f'saving checkpoints and logs to {experiment_path}')\n",
    "\n",
    "log_callback = ModelAndLogSavingCallback(model, experiment_path)\n",
    "\n",
    "# generating callback\n",
    "from src.generating.generating import recurrent_generate\n",
    "from src.generating.embedded_generating_seeds import seed_generators\n",
    "from src.data_processing.common.helpers import pipe\n",
    "from src.data_processing.embedding_sparse_notes.reverse_transform import np2sparse\n",
    "\n",
    "SEED_LENGTH = 20\n",
    "GENERATED_SEQ_LENGTH = 300\n",
    "METHOD = 'random_noise_seed'\n",
    "\n",
    "seed_generator = lambda: seed_generators[METHOD](\n",
    "    SEED_LENGTH, INPUT_SIZE, BATCH_SIZE)\n",
    "\n",
    "sample_generator = lambda model, seed: recurrent_generate(\n",
    "    model, seed, GENERATED_SEQ_LENGTH, WINDOW_SIZE, is_binary=False)\n",
    "\n",
    "sparse_sample_generator = lambda model, seed: pipe(\n",
    "    sample_generator(model, seed),\n",
    "    lambda batch_of_samples: [np2sparse(sample, word_vectors) for sample in batch_of_samples]\n",
    ")\n",
    "\n",
    "print(f'generating sequences of {GENERATED_SEQ_LENGTH} using {METHOD}')\n",
    "\n",
    "gen_callback = GeneratingAndPlottingCallback(model, sparse_sample_generator, seed_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer=K.optimizers.Adam(), \n",
    "    metrics=[\"mean_squared_error\"],\n",
    "#     callbacks=[log_callback, gen_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre training code\n",
    "from time import time\n",
    "epochs_elapsed = 0\n",
    "minutes_elapsed = 0\n",
    "\n",
    "data_gen = dataset_gen(vectorized_tracks, WINDOW_SIZE, BATCH_SIZE)\n",
    "test_gen = dataset_gen(vectorized_tracks, WINDOW_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 0s - loss: 5.7364 - mean_squared_error: 5.7364"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8011c7e071f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m       \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programowanko/artificial-music/src/training/lstm/../../../src/training/common/training_callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         _, axs = plt.subplots(nrows=4, ncols=4, figsize=(30, 10),\n",
      "\u001b[0;32m<ipython-input-15-e80f2f92db43>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(model, seed)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m sparse_sample_generator = lambda model, seed: pipe(\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0msample_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mbatch_of_samples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp2sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_of_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-15-e80f2f92db43>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(model, seed)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m sample_generator = lambda model, seed: recurrent_generate(\n\u001b[0;32m---> 26\u001b[0;31m     model, seed, GENERATED_SEQ_LENGTH, WINDOW_SIZE, is_binary=False)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m sparse_sample_generator = lambda model, seed: pipe(\n",
      "\u001b[0;32m~/programowanko/artificial-music/src/training/lstm/../../../src/generating/generating.py\u001b[0m in \u001b[0;36mrecurrent_generate\u001b[0;34m(model, seed, seq_length, window_size, is_binary)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnext_timestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_binary\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_timestep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0maccum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_timestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "STEPS_PER_EPOCH = 100\n",
    "TEST_STEPS = 100\n",
    "\n",
    "start_time = time()\n",
    "model.fit_generator(\n",
    "    data_gen,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_gen,\n",
    "    validation_steps=TEST_STEPS,\n",
    "    callbacks=[log_callback, gen_callback]\n",
    ")\n",
    "\n",
    "minutes_elapsed += (time() - start_time) // 60\n",
    "epochs_elapsed += EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
