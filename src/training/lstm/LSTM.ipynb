{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing dataset, splitting tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D#3,C4', 'D#3,C4', 'D#3,C4', ..., '<UNKNOWN>', '<UNKNOWN>',\n",
       "       '<TRACK_END>'], dtype='<U27')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "proj_base_path = '../../../'\n",
    "data_base_path = '../../../datasets'\n",
    "models_base_path = '../../../pretrained_models'\n",
    "sys.path.append(os.path.join(os.getcwd(), proj_base_path))\n",
    "\n",
    "dataset_path = 'numpy/pokemon100ms_no_vel_transposed/meta/'\n",
    "dataset_file = '_dicted_dataset_ignore_ratio=0.05.npy'\n",
    "word_vectors_file = '_word_vectors_1000_ignore_ratio=0.05.wv'\n",
    "\n",
    "track_path = os.path.join(data_base_path, dataset_path, dataset_file)\n",
    "word_vectors_path = os.path.join(data_base_path, dataset_path, word_vectors_file)\n",
    "\n",
    "track = np.load(track_path)\n",
    "\n",
    "track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.embedding_sparse_notes.common import TRACK_END, UNKNOWN_FRAME\n",
    "\n",
    "track_split_points = np.where(track == TRACK_END)[0]\n",
    "\n",
    "# + 1, so split happens after <TRACK_END>, [:-1] to skip last, empty partition\n",
    "tracks = [t.tolist() for t in np.split(track, track_split_points + 1)][:-1]\n",
    "# tracks is now a list of lists of frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading embedding + encoding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 16), (2197, 16), (1920, 16), (361, 16), (552, 16), (1008, 16), (533, 16), (552, 16), (552, 16), (533, 16), (1008, 16), (361, 16), (2197, 16), (2197, 16), (2197, 16), (361, 16), (1920, 16), (552, 16), (1008, 16), (552, 16), (717, 16), (717, 16), (552, 16), (1008, 16), (552, 16), (1920, 16), (361, 16), (2197, 16), (2197, 16), (1920, 16), (552, 16), (1622, 16), (717, 16), (386, 16), (1008, 16), (1622, 16), (552, 16), (552, 16), (1622, 16), (1008, 16), (386, 16), (717, 16), (552, 16), (1622, 16), (1920, 16), (361, 16), (2197, 16), (2197, 16), (1920, 16), (361, 16), (552, 16), (717, 16), (1008, 16), (386, 16), (552, 16), (1008, 16), (1008, 16), (552, 16), (386, 16), (1008, 16), (1622, 16), (552, 16), (361, 16), (1920, 16), (2197, 16), (717, 16), (361, 16), (2197, 16), (1008, 16), (533, 16), (533, 16), (386, 16), (386, 16), (533, 16), (533, 16), (361, 16), (2197, 16), (1008, 16), (361, 16), (717, 16), (717, 16), (1622, 16), (2197, 16), (1920, 16), (533, 16), (361, 16), (533, 16), (533, 16), (361, 16), (1920, 16), (2197, 16), (1622, 16), (717, 16), (717, 16), (2197, 16), (361, 16), (717, 16), (1008, 16), (533, 16), (361, 16), (361, 16), (533, 16), (717, 16), (1920, 16), (361, 16), (2197, 16), (717, 16), (717, 16), (361, 16), (1622, 16), (2197, 16), (1920, 16), (1008, 16), (533, 16), (533, 16), (361, 16), (361, 16), (533, 16), (533, 16), (1008, 16), (361, 16), (1920, 16), (2197, 16), (1622, 16), (361, 16), (717, 16), (361, 16), (1622, 16), (1008, 16), (361, 16), (1920, 16), (361, 16), (361, 16), (1920, 16), (361, 16), (1622, 16), (361, 16), (717, 16), (361, 16), (361, 16), (2197, 16), (1622, 16), (1008, 16), (361, 16), (1920, 16), (1920, 16), (361, 16), (1008, 16), (1622, 16), (2197, 16), (361, 16), (361, 16), (717, 16), (361, 16), (1622, 16), (361, 16), (1008, 16), (2197, 16), (1920, 16), (1920, 16), (1008, 16), (2197, 16), (361, 16), (1622, 16), (361, 16), (1920, 16), (361, 16), (552, 16), (1622, 16), (361, 16), (1008, 16), (1920, 16), (533, 16), (533, 16), (1920, 16), (1008, 16), (361, 16), (1622, 16), (552, 16), (361, 16), (1920, 16), (1920, 16), (1622, 16), (552, 16), (386, 16), (1008, 16), (386, 16), (386, 16), (717, 16), (717, 16), (533, 16), (386, 16), (386, 16), (552, 16), (1008, 16), (386, 16), (1622, 16), (552, 16), (1920, 16), (1622, 16), (386, 16), (552, 16), (386, 16), (386, 16), (533, 16), (717, 16), (533, 16), (386, 16), (552, 16), (386, 16), (1622, 16), (2197, 16), (361, 16), (1622, 16), (386, 16), (361, 16), (386, 16), (533, 16), (717, 16), (717, 16), (533, 16), (386, 16), (386, 16), (361, 16), (2197, 16), (1622, 16), (386, 16), (361, 16), (533, 16), (361, 16), (552, 16), (717, 16), (717, 16), (552, 16), (361, 16), (533, 16), (386, 16), (361, 16), (386, 16), (1622, 16), "
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = KeyedVectors.load(word_vectors_path, mmap='r')\n",
    "\n",
    "def vectorize_frame(frame):\n",
    "    return wv[frame] if frame in wv else wv[UNKNOWN_FRAME]\n",
    "\n",
    "vectorized_tracks = [np.array([vectorize_frame(f) for f in t]) for t in tracks]\n",
    "for v in vectorized_tracks: print(v.shape, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 31, 16), (5, 31, 16))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataset_gen(tracks, window_size_range=(20, 300), batch_size=16):\n",
    "    \"\"\"\n",
    "    tracks - list of np.arrays of shape (track_length, frame_size)\n",
    "    window_size - length of generated batch\n",
    "    batch_size - number of sequences in batch\n",
    "    \"\"\"\n",
    "    max_window_size = min([len(t) for t in tracks]) - 3\n",
    "    while True:\n",
    "        window_size = np.random.randint(window_size_range[0], min(max_window_size, window_size_range[1]))\n",
    "        # select #batch_size tracks\n",
    "        selected_track_indicies = [np.random.randint(0, len(tracks)) for _ in range(batch_size)]\n",
    "        # select sequence starting point for each track\n",
    "        sequence_indicies = [np.random.randint(0, len(tracks[sti]) - window_size - 2)\n",
    "                             for sti in selected_track_indicies]\n",
    "        \n",
    "        \n",
    "        # create slices for x and y\n",
    "        x_slice = lambda seqi: np.s_[seqi:seqi + window_size]\n",
    "        y_slice = lambda seqi: np.s_[seqi + 1:seqi + window_size + 1]\n",
    "        \n",
    "        x = [tracks[sti][x_slice(seqi)] for sti, seqi in zip(selected_track_indicies, sequence_indicies)]\n",
    "        y = [tracks[sti][y_slice(seqi)] for sti, seqi in zip(selected_track_indicies, sequence_indicies)]\n",
    "\n",
    "        yield np.stack(x), np.stack(y)\n",
    "        \n",
    "x, y = next(dataset_gen(vectorized_tracks, (10, 50), 5))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as K\n",
    "\n",
    "INPUT_SIZE = 16\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = INPUT_SIZE\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "WINDOW_SIZE_RANGE = (20, 300)\n",
    "\n",
    "INPUT_SHAPE = (None, INPUT_SIZE)\n",
    "# None allows for variable seq_length between batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '../../../pretrained_models/lstm/embedded_16_128md_e1_t2019-10-08T18:06:50.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-43ecad040011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# or load saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lstm/embedded_16_128md_e1_t2019-10-08T18:06:50.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m       h5py is not None and (\n\u001b[1;32m    145\u001b[0m           isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../../../pretrained_models/lstm/embedded_16_128md_e1_t2019-10-08T18:06:50.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# or load saved model\n",
    "model_path = 'lstm/embedded_16_128md_e1_t2019-10-08T18:06:50.h5'\n",
    "model = K.models.load_model(os.path.join(models_base_path, model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or create new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1010 19:02:01.902128 4577134016 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = K.models.Sequential([\n",
    "    K.layers.LSTM(\n",
    "        HIDDEN_SIZE,\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        return_sequences=True,\n",
    "    ),\n",
    "    K.layers.Dense(\n",
    "        OUTPUT_SIZE,\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam', \n",
    "    metrics=[\"mean_squared_error\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoints and logs to ../../../pretrained_models/lstm/embedded_16_128\n",
      "generating sequences of 400 using const_frame_seed_noise\n"
     ]
    }
   ],
   "source": [
    "from src.training.common.training_callbacks import ModelAndLogSavingCallback, GeneratingAndPlottingCallback\n",
    "\n",
    "# logging callback\n",
    "logging_path = 'lstm'\n",
    "experiment_name = f'embedded_{INPUT_SIZE}_{HIDDEN_SIZE}'\n",
    "experiment_path = os.path.join(models_base_path, logging_path, experiment_name)\n",
    "os.makedirs(experiment_path, exist_ok=True)\n",
    "print(f'saving checkpoints and logs to {experiment_path}')\n",
    "\n",
    "# logging disabled for now\n",
    "log_callback = ModelAndLogSavingCallback(model, experiment_path)\n",
    "\n",
    "# generating callback\n",
    "from src.generating.generating import recurrent_generate\n",
    "from src.generating.embedded_generating_seeds import seed_generators\n",
    "from src.data_processing.common.helpers import pipe\n",
    "from src.data_processing.embedding_sparse_notes.reverse_transform import np2sparse\n",
    "\n",
    "SEED_LENGTH = 20\n",
    "GENERATED_SEQ_LENGTH = 400\n",
    "GENERATING_WINDOW_SIZE = 100\n",
    "METHOD = 'const_frame_seed_noise'\n",
    "\n",
    "seed_generator = lambda: seed_generators[METHOD](\n",
    "    SEED_LENGTH, INPUT_SIZE, word_vectors=wv, batch_size=BATCH_SIZE)\n",
    "\n",
    "sample_generator = lambda model, seed: recurrent_generate(\n",
    "    model, seed, GENERATED_SEQ_LENGTH, GENERATING_WINDOW_SIZE, is_binary=False)\n",
    "\n",
    "sparse_sample_generator = lambda model, seed: pipe(\n",
    "    sample_generator(model, seed),\n",
    "    lambda batch_of_samples: [np2sparse(sample, wv)[0] for sample in batch_of_samples]\n",
    ")\n",
    "\n",
    "print(f'generating sequences of {GENERATED_SEQ_LENGTH} using {METHOD}')\n",
    "\n",
    "gen_callback = GeneratingAndPlottingCallback(model, sparse_sample_generator, seed_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre training code\n",
    "from time import time\n",
    "epochs_elapsed = 0\n",
    "minutes_elapsed = 0\n",
    "\n",
    "data_gen = dataset_gen(vectorized_tracks, WINDOW_SIZE_RANGE, BATCH_SIZE)\n",
    "test_gen = dataset_gen(vectorized_tracks, WINDOW_SIZE_RANGE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1010 19:02:05.672058 4577134016 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/10 [=======================>......] - ETA: 0s - loss: 16.5788 - mean_squared_error: 16.9124"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/10 [==============================] - 7s 672ms/step - loss: 16.3740 - mean_squared_error: 16.7515 - val_loss: 17.1380 - val_mean_squared_error: 17.1380\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "STEPS_PER_EPOCH = 10\n",
    "TEST_STEPS = 1\n",
    "\n",
    "start_time = time()\n",
    "model.fit_generator(\n",
    "    data_gen,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_gen,\n",
    "    validation_steps=TEST_STEPS,\n",
    "    callbacks=[log_callback, gen_callback]\n",
    ")\n",
    "\n",
    "minutes_elapsed += (time() - start_time) // 60\n",
    "epochs_elapsed += EPOCHS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
